import streamlit as st
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import (
    accuracy_score,
    roc_auc_score,
    precision_score,
    recall_score,
    f1_score,
    roc_curve,
)

import matplotlib.pyplot as plt

st.set_page_config(page_title="ë‹¤ì¤‘ Logit ëª¨ë¸", layout="wide")
st.title("ğŸ” ë‹¤ì¤‘ Logit (ë¡œì§€ìŠ¤í‹± íšŒê·€) + DT + Hybrid ëª¨ë¸ ìë™ êµ¬ì¶•")

# 1ï¸âƒ£ ë°ì´í„° ì—…ë¡œë“œ
st.sidebar.header("1ï¸âƒ£ ë°ì´í„° ì—…ë¡œë“œ")
uploaded_file = st.sidebar.file_uploader("ì¸ì½”ë”©ëœ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["csv"])

if uploaded_file is None:
    st.info("ì™¼ìª½ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    st.stop()

df = pd.read_csv(uploaded_file)
st.success("âœ… ë°ì´í„° ì—…ë¡œë“œ ë° ì½ê¸°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
st.subheader("ğŸ“Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
st.dataframe(df.head())

# 2ï¸âƒ£ ì´ì§„ ë¶„ë¥˜ ë³€ìˆ˜(Y) íƒìƒ‰
st.sidebar.header("2ï¸âƒ£ ì˜ˆì¸¡ ëŒ€ìƒ ë³€ìˆ˜(Y) ì„ íƒ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)")
binary_cols = [col for col in df.columns if df[col].nunique() == 2]

if not binary_cols:
    st.error("âŒ ì´ì§„ ë¶„ë¥˜ ë³€ìˆ˜(Y)ê°€ ì—†ì–´ Logit/DT ëª¨ë¸ì„ êµ¬ì¶•í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

st.write("**ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì´ì§„ ë¶„ë¥˜ ë³€ìˆ˜ ëª©ë¡(Y):**")
st.write(binary_cols)

selected_targets = st.sidebar.multiselect(
    "ì˜ˆì¸¡í•  Y ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥):",
    options=binary_cols,
    default=binary_cols,  # ê¸°ë³¸: ì „ë¶€ ì„ íƒ
)

if not selected_targets:
    st.warning("âš  ìµœì†Œ í•œ ê°œ ì´ìƒì˜ Y ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()

# 3ï¸âƒ£ X (íŠ¹ì§• ë³€ìˆ˜) ì„ íƒ
st.sidebar.header("3ï¸âƒ£ íŠ¹ì§• ë³€ìˆ˜(X) ì„ íƒ")
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

if not numeric_cols:
    st.error("âŒ ìˆ˜ì¹˜í˜• íŠ¹ì§• ë³€ìˆ˜ê°€ ì—†ì–´ ëª¨ë¸ í›ˆë ¨ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
    st.stop()

feature_cols = st.sidebar.multiselect(
    "X ë³€ìˆ˜(íŠ¹ì§•)ë¥¼ ì„ íƒí•˜ì„¸ìš”.", options=numeric_cols, default=numeric_cols
)

if not feature_cols:
    st.error("âš  ìµœì†Œ í•œ ê°œ ì´ìƒì˜ X ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()

# 4ï¸âƒ£ í›ˆë ¨ ì„¤ì • (ëœë¤ ì‹œë“œëŠ” ë‚´ë¶€ì—ì„œ ê³ ì •)
st.sidebar.header("4ï¸âƒ£ í›ˆë ¨ ì„¤ì •")
test_size = st.sidebar.slider("í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨", 0.1, 0.4, 0.3, step=0.05)
RANDOM_STATE = 42  # ğŸ‘ˆ ëœë¤ ì‹œë“œ ê³ ì • (ì…ë ¥ì°½ ì œê±°)


# ğŸš€ ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰
if st.sidebar.button("ëª¨ë“  ëª¨ë¸ í›ˆë ¨ ì‹œì‘"):
    # ìš”ì•½ìš© ê²°ê³¼ (Logit ê¸°ì¤€ë§Œ ëª¨ì•„ì„œ ë³¼ ìˆ˜ë„ ìˆìŒ)
    summary_rows = []

    for target in selected_targets:
        st.markdown(f"---\n## ğŸ¯ ì˜ˆì¸¡ ëŒ€ìƒ(Y): `{target}`")

        # 1. X, y êµ¬ì„±
        X = df[feature_cols].copy()
        if target in X.columns:
            X = X.drop(columns=[target])  # íƒ€ê¹ƒì´ Xì— ì„ì—¬ ìˆìœ¼ë©´ ì œê±°

        y = df[target]

        if y.nunique() != 2:
            st.warning(f"`{target}` ë³€ìˆ˜ëŠ” ì´ì§„ ë¶„ë¥˜ê°€ ì•„ë‹ˆë¯€ë¡œ ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        # 2. ë°ì´í„° ì •ë¦¬ (ê²°ì¸¡ì¹˜ & ë¬´í•œëŒ€ ì œê±°)
        data_xy = pd.concat([X, y], axis=1)
        data_xy = data_xy.replace([np.inf, -np.inf], np.nan)

        before = len(data_xy)
        data_xy = data_xy.dropna()
        after = len(data_xy)

        if after < 50:
            st.warning(f"`{target}` ì •ë¦¬ í›„ ìƒ˜í”Œ ìˆ˜ê°€ {after}ê°œë¡œ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        st.write(
            f"ğŸ§¹ `{target}` : ê²°ì¸¡ì¹˜/ë¬´í•œëŒ€ ì œê±° í›„ **{before - after}ê°œ ì‚­ì œ**, "
            f"ë‚¨ì€ ìƒ˜í”Œ **{after}ê°œ**"
        )

        X_clean = data_xy.drop(columns=[target])
        y_clean = data_xy[target]

        if y_clean.nunique() != 2:
            st.warning(f"`{target}` ì •ë¦¬ í›„ í•œ ê°œì˜ í´ë˜ìŠ¤ë§Œ ë‚¨ì•„ ëª¨ë¸ í›ˆë ¨ ë¶ˆê°€. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        # 3. í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬
        try:
            X_train, X_test, y_train, y_test = train_test_split(
                X_clean,
                y_clean,
                test_size=test_size,
                random_state=RANDOM_STATE,
                stratify=y_clean,
            )
        except ValueError as e:
            st.warning(f"`{target}` í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬ ì˜¤ë¥˜: {e}")
            continue

        # 4. ì„¸ ê°€ì§€ ëª¨ë¸ ì •ì˜
        logit_model = LogisticRegression(max_iter=1000, solver="liblinear", random_state=RANDOM_STATE)
        dt_model = DecisionTreeClassifier(random_state=RANDOM_STATE)

        # 5. ëª¨ë¸ í›ˆë ¨
        try:
            logit_model.fit(X_train, y_train)
            dt_model.fit(X_train, y_train)
        except ValueError as e:
            st.warning(f"`{target}` ëª¨ë¸ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue

        # 6. ì˜ˆì¸¡ (í™•ë¥  í¬í•¨)
        y_pred_logit = logit_model.predict(X_test)
        y_proba_logit = logit_model.predict_proba(X_test)[:, 1]

        y_pred_dt = dt_model.predict(X_test)
        y_proba_dt = dt_model.predict_proba(X_test)[:, 1]

        # Hybrid: Logit + DT í‰ê·  í™•ë¥ 
        y_proba_hybrid = (y_proba_logit + y_proba_dt) / 2
        y_pred_hybrid = (y_proba_hybrid >= 0.5).astype(int)

        # 7. ì„±ëŠ¥ì§€í‘œ ê³„ì‚°
        def get_metrics(y_true, y_pred, y_proba):
            acc = accuracy_score(y_true, y_pred)
            prec = precision_score(y_true, y_pred, zero_division=0)
            rec = recall_score(y_true, y_pred, zero_division=0)
            f1 = f1_score(y_true, y_pred, zero_division=0)
            try:
                auc = roc_auc_score(y_true, y_proba)
            except ValueError:
                auc = np.nan
            return acc, prec, rec, f1, auc

        acc_logit, prec_logit, rec_logit, f1_logit, auc_logit = get_metrics(
            y_test, y_pred_logit, y_proba_logit
        )
        acc_dt, prec_dt, rec_dt, f1_dt, auc_dt = get_metrics(
            y_test, y_pred_dt, y_proba_dt
        )
        acc_hyb, prec_hyb, rec_hyb, f1_hyb, auc_hyb = get_metrics(
            y_test, y_pred_hybrid, y_proba_hybrid
        )

        # 8. ğŸ“Š ì„±ëŠ¥í‰ê°€ í…Œì´ë¸” (DT / Logit / Hybrid)
        st.subheader("ğŸ“Š ì„±ëŠ¥í‰ê°€ (DT / Logit / Hybrid)")

        metrics_df = pd.DataFrame(
            {
                "ëª¨ë¸": ["Logit", "DT", "Hybrid"],
                "Accuracy": [acc_logit, acc_dt, acc_hyb],
                "Precision": [prec_logit, prec_dt, prec_hyb],
                "Recall": [rec_logit, rec_dt, rec_hyb],
                "F1-score": [f1_logit, f1_dt, f1_hyb],
                "ROC-AUC": [auc_logit, auc_dt, auc_hyb],
            }
        )

        st.dataframe(metrics_df)

        # 9. ROC ê³¡ì„  (DT / Logit / Hybrid)
        st.subheader("ğŸ“ˆ ROC ê³¡ì„  (DT / Logit / Hybrid)")

        fpr_logit, tpr_logit, _ = roc_curve(y_test, y_proba_logit)
        fpr_dt, tpr_dt, _ = roc_curve(y_test, y_proba_dt)
        fpr_hyb, tpr_hyb, _ = roc_curve(y_test, y_proba_hybrid)

        fig, ax = plt.subplots()
        ax.plot(fpr_logit, tpr_logit, label=f"Logit (AUC={auc_logit:.3f})")
        ax.plot(fpr_dt, tpr_dt, label=f"DT (AUC={auc_dt:.3f})")
        ax.plot(fpr_hyb, tpr_hyb, label=f"Hybrid (AUC={auc_hyb:.3f})")
        ax.plot([0, 1], [0, 1], linestyle="--")
        ax.set_xlabel("False Positive Rate")
        ax.set_ylabel("True Positive Rate")
        ax.set_title(f"ROC ê³¡ì„  - {target}")
        ax.legend(loc="lower right")
        st.pyplot(fig)

        # ìš”ì•½ìš©(ì›í•˜ë©´ ë‚˜ì¤‘ì— í•œ ë²ˆì— ë¹„êµ ê°€ëŠ¥)
        summary_rows.append(
            {
                "Target (Y)": target,
                "Logit_Accuracy": round(acc_logit, 4),
                "Logit_ROC_AUC": round(auc_logit, 4) if not np.isnan(auc_logit) else None,
                "DT_Accuracy": round(acc_dt, 4),
                "DT_ROC_AUC": round(auc_dt, 4) if not np.isnan(auc_dt) else None,
                "Hybrid_Accuracy": round(acc_hyb, 4),
                "Hybrid_ROC_AUC": round(auc_hyb, 4) if not np.isnan(auc_hyb) else None,
            }
        )

    # ì „ì²´ íƒ€ê¹ƒì— ëŒ€í•œ ìš”ì•½í‘œ (ì˜µì…˜)
    if summary_rows:
        st.markdown("---")
        st.subheader("ğŸ“Š ì„±ëŠ¥ ìš”ì•½ (ê° Yë³„ / ëª¨ë¸ë³„ Accuracy & ROC-AUC)")
        st.dataframe(pd.DataFrame(summary_rows))
    else:
        st.warning("âš  ì„±ê³µì ìœ¼ë¡œ í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

else:
    st.info("ğŸ‘ˆ ì™¼ìª½ ì„¤ì •ì„ ì™„ë£Œí•œ í›„ **ëª¨ë“  ëª¨ë¸ í›ˆë ¨ ì‹œì‘** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
