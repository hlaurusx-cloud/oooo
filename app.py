import streamlit as st
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

st.set_page_config(page_title="ä¿¡ç”¨è¯„ä¼°æ¨¡å‹ (HTML æ•°æ®ç‰ˆ)", layout="wide")

st.title("ğŸ’³ æ™ºèƒ½å‹ä¿¡ç”¨è¯„åˆ†æ¨¡å‹ï¼ˆé€»è¾‘å›å½’ï¼‰")
st.write("ç›´æ¥ä½¿ç”¨ä¸Šä¼ çš„ **HTML æ–‡ä»¶ä¸­çš„è¡¨æ ¼æ•°æ®**ï¼Œè¿›è¡Œå»ºæ¨¡å’Œå¯è§†åŒ–ã€‚")


# ------------------------------------------------------------
# 1. ä¸Šä¼  HTML æ–‡ä»¶å¹¶è§£æä¸ºå¤šä¸ª DataFrame
# ------------------------------------------------------------
st.sidebar.header("1ï¸âƒ£ ä¸Šä¼  HTML æ•°æ®æ–‡ä»¶")

uploaded_file = st.sidebar.file_uploader(
    "è¯·é€‰æ‹©å·²ç»å¤„ç†å¥½çš„ HTML æ–‡ä»¶",
    type=["html", "htm"]
)

if uploaded_file is None:
    st.warning("è¯·åœ¨å·¦ä¾§ä¸Šä¼  HTML æ–‡ä»¶ï¼ˆ.html æˆ– .htmï¼‰")
    st.stop()

# è¯» HTML é‡Œçš„æ‰€æœ‰ <table> æ ‡ç­¾
try:
    tables = pd.read_html(uploaded_file)
except Exception as e:
    st.error(f"è¯»å– HTML å¤±è´¥ï¼š{e}")
    st.stop()

st.sidebar.success(f"å·²ä» HTML ä¸­è§£æå‡º {len(tables)} ä¸ªè¡¨æ ¼")

# é€‰æ‹©ç”¨äºå»ºæ¨¡çš„è¡¨æ ¼ index
table_index = st.sidebar.number_input(
    "é€‰æ‹©ç”¨äºå»ºæ¨¡çš„æ•°æ®è¡¨ç´¢å¼•ï¼ˆä» 0 å¼€å§‹ï¼‰",
    min_value=0,
    max_value=len(tables)-1,
    value=0,
    step=1
)

df = tables[table_index]
st.write(f"### ä½¿ç”¨çš„è¡¨æ ¼ (index = {table_index}) æ•°æ®é¢„è§ˆ")
st.dataframe(df.head())


# ------------------------------------------------------------
# 2. é€‰æ‹©ç›®æ ‡å˜é‡ï¼ˆå¥½/åå®¢æˆ·æ ‡ç­¾ï¼‰
# ------------------------------------------------------------
st.sidebar.header("2ï¸âƒ£ è®¾ç½®ç›®æ ‡å˜é‡ï¼ˆå¥½/åæ ‡ç­¾ï¼‰")

# é€‰æ‹©ç›®æ ‡åˆ—
target_col = st.sidebar.selectbox(
    "è¯·é€‰æ‹©ç›®æ ‡å˜é‡åˆ—ï¼ˆä¾‹å¦‚ target / loan_status ç­‰ï¼‰",
    options=df.columns
)

# æŸ¥çœ‹ç›®æ ‡åˆ—çš„å”¯ä¸€å–å€¼
unique_vals = df[target_col].dropna().unique()
st.sidebar.write("è¯¥åˆ—çš„å”¯ä¸€å–å€¼ï¼š", unique_vals)

if len(unique_vals) < 2:
    st.error("ç›®æ ‡åˆ—çš„å–å€¼ç§ç±»å°‘äº 2ï¼Œæ— æ³•è¿›è¡ŒäºŒåˆ†ç±»å»ºæ¨¡ã€‚è¯·æ¢ä¸€ä¸ªç›®æ ‡åˆ—ã€‚")
    st.stop()

# é€‰æ‹©â€œå¥½ / åâ€å¯¹åº”çš„å€¼
bad_value = st.sidebar.selectbox("è¯·é€‰æ‹©ã€åå®¢æˆ· / è¿çº¦ã€çš„æ ‡ç­¾å€¼", options=unique_vals)
good_value = st.sidebar.selectbox(
    "è¯·é€‰æ‹©ã€å¥½å®¢æˆ· / æ­£å¸¸ã€çš„æ ‡ç­¾å€¼",
    options=[v for v in unique_vals if v != bad_value]
)

st.write(f"**ç›®æ ‡åˆ—ï¼š** `{target_col}`ï¼Œå = `{bad_value}`ï¼Œå¥½ = `{good_value}`")


# ------------------------------------------------------------
# 3. æŒ‰å¥½/åå„æŠ½æ · 15000 æ¡
# ------------------------------------------------------------
st.sidebar.header("3ï¸âƒ£ æŠ½æ ·ä¸æ¨¡å‹è®­ç»ƒ")
sample_n = 15000
test_size = st.sidebar.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.4, 0.3, 0.05)

if st.sidebar.button("å¼€å§‹æŠ½æ · + è®­ç»ƒæ¨¡å‹"):
    # åˆ†æˆå¥½/åä¸¤éƒ¨åˆ†
    bad_df = df[df[target_col] == bad_value]
    good_df = df[df[target_col] == good_value]

    st.write("### åŸå§‹æ•°æ®ä¸­æ ‡ç­¾åˆ†å¸ƒ")
    st.write(f"- åå®¢æˆ·({bad_value})ï¼š{len(bad_df)} æ¡")
    st.write(f"- å¥½å®¢æˆ·({good_value})ï¼š{len(good_df)} æ¡")

    # æŠ½æ ·ï¼ˆå¦‚æœä¸è¶³ 15000 å°±æ”¾å›é‡‡æ ·ï¼‰
    bad_sample = bad_df.sample(
        n=sample_n,
        replace=len(bad_df) < sample_n,
        random_state=42
    )
    good_sample = good_df.sample(
        n=sample_n,
        replace=len(good_df) < sample_n,
        random_state=42
    )

    sampled_df = pd.concat([bad_sample, good_sample], axis=0)
    sampled_df = sampled_df.sample(frac=1, random_state=42).reset_index(drop=True)

    st.success(f"å·²ä»å¥½/åå„æŠ½å– {sample_n} æ¡æ ·æœ¬ï¼Œå…± {len(sampled_df)} æ¡ã€‚")
    st.write("æŠ½æ ·åæ•°æ®é¢„è§ˆï¼š")
    st.dataframe(sampled_df.head())

    # --------------------------------------------------------
    # 4. ç‰¹å¾ / ç›®æ ‡æ‹†åˆ†ï¼ˆåªç”¨æ•°å€¼å‹ç‰¹å¾ï¼‰
    # --------------------------------------------------------
    y = sampled_df[target_col]
    X = sampled_df.drop(columns=[target_col])

    # åªå–æ•°å€¼å‹åˆ—ï¼ˆHTML å·²ç¼–ç å¥½çš„è¯ï¼Œè¿™é‡Œä¸€èˆ¬éƒ½æ˜¯æ•°å€¼ + å°‘é‡å­—ç¬¦ä¸²åˆ—ï¼‰
    X_num = X.select_dtypes(include=[np.number])
    st.write(f"ç”¨äºå»ºæ¨¡çš„æ•°å€¼å‹ç‰¹å¾ä¸ªæ•°ï¼š{X_num.shape[1]}")

    if X_num.shape[1] == 0:
        st.error("æ²¡æœ‰æ£€æµ‹åˆ°æ•°å€¼å‹ç‰¹å¾åˆ—ï¼Œæ— æ³•è¿›è¡Œé€»è¾‘å›å½’ã€‚è¯·ç¡®è®¤æ•°æ®æ˜¯å¦å·²ç»ç¼–ç /æ•°å€¼åŒ–ã€‚")
        st.stop()

    # --------------------------------------------------------
    # 5. è®­ç»ƒ / æµ‹è¯•é›†åˆ’åˆ† & æ ‡å‡†åŒ–
    # --------------------------------------------------------
    X_train, X_test, y_train, y_test = train_test_split(
        X_num, y,
        test_size=test_size,
        random_state=42,
        stratify=y
    )

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # --------------------------------------------------------
    # 6. é€»è¾‘å›å½’æ¨¡å‹è®­ç»ƒ
    # --------------------------------------------------------
    model = LogisticRegression(
        max_iter=1000,
        n_jobs=-1,
        solver="lbfgs"
    )
    model.fit(X_train_scaled, y_train)

    st.success("âœ… é€»è¾‘å›å½’æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

    # --------------------------------------------------------
    # 7. æ¨¡å‹è¯„ä¼°
    # --------------------------------------------------------
    y_pred = model.predict(X_test_scaled)
    if len(np.unique(y)) == 2:
        # æŠŠâ€œåå®¢æˆ·â€çš„æ¦‚ç‡ä½œä¸ºé¢„æµ‹æ¦‚ç‡ï¼ˆéœ€è¦æ‰¾å¯¹åº”çš„åˆ—ï¼‰
        bad_index = list(model.classes_).index(bad_value)
        y_pred_proba = model.predict_proba(X_test_scaled)[:, bad_index]
    else:
        y_pred_proba = None

    st.subheader("ğŸ“Š åˆ†ç±»æŠ¥å‘Š (Classification Report)")
    st.text(classification_report(y_test, y_pred))

    st.subheader("ğŸ“‰ æ··æ·†çŸ©é˜µ (Confusion Matrix)")
    cm = confusion_matrix(y_test, y_pred)
    cm_df = pd.DataFrame(
        cm,
        index=[f"çœŸå®_{c}" for c in model.classes_],
        columns=[f"é¢„æµ‹_{c}" for c in model.classes_]
    )
    st.dataframe(cm_df)

    if y_pred_proba is not None:
        try:
            auc = roc_auc_score((y_test == bad_value).astype(int), y_pred_proba)
            st.subheader("ğŸ“ˆ ROC-AUC")
            st.write(f"ROC-AUCï¼š**{auc:.4f}**ï¼ˆä»¥åå®¢æˆ· `{bad_value}` ä¸ºæ­£ç±»ï¼‰")
        except Exception as e:
            st.info(f"è®¡ç®— ROC-AUC æ—¶å‡ºé”™ï¼š{e}")

    # --------------------------------------------------------
    # 8. æŸ¥çœ‹ç‰¹å¾ç³»æ•°ï¼ˆé‡è¦æ€§ï¼‰
    # --------------------------------------------------------
    st.subheader("ğŸ” ç‰¹å¾ç³»æ•°ï¼ˆç»å¯¹å€¼è¶Šå¤§å½±å“è¶Šå¤§ï¼‰")
    coef_df = pd.DataFrame({
        "feature": X_num.columns,
        "coef": model.coef_[0]
    })
    coef_df["abs_coef"] = coef_df["coef"].abs()
    coef_df = coef_df.sort_values("abs_coef", ascending=False)

    st.dataframe(coef_df[["feature", "coef"]].head(30))

else:
    st.info("åœ¨ä¾§è¾¹æ è®¾ç½®å¥½ **HTML æ–‡ä»¶ + ç›®æ ‡åˆ— + å¥½/åæ ‡ç­¾** åï¼Œç‚¹å‡»ã€Œå¼€å§‹æŠ½æ · + è®­ç»ƒæ¨¡å‹ã€ã€‚")
