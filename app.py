import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_auc_score

st.set_page_config(page_title="å¤šç›®æ ‡ Logit æ¨¡å‹", layout="wide")
st.title("ğŸ” å¤šç›®æ ‡ Logitï¼ˆé€»è¾‘å›å½’ï¼‰æ¨¡å‹è‡ªåŠ¨å»ºæ¨¡")

# 1ï¸âƒ£ ä¸Šä¼ æ•°æ®
st.sidebar.header("1ï¸âƒ£ ä¸Šä¼ æ•°æ®")
uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ å·²ç¼–ç å¥½çš„ CSV æ–‡ä»¶", type=["csv"])

if uploaded_file is None:
    st.info("è¯·åœ¨å·¦ä¾§ä¸Šä¼ ä¸€ä¸ª CSV æ–‡ä»¶ã€‚")
    st.stop()

df = pd.read_csv(uploaded_file)
st.success("âœ… æ•°æ®ä¸Šä¼ å¹¶è¯»å–æˆåŠŸï¼")
st.subheader("æ•°æ®é¢„è§ˆ")
st.dataframe(df.head())

# 2ï¸âƒ£ æ‰¾æ‰€æœ‰äºŒåˆ†ç±»å˜é‡ä½œä¸ºç›®æ ‡å€™é€‰
st.sidebar.header("2ï¸âƒ£ é€‰æ‹©ç›®æ ‡ Yï¼ˆå¯å¤šé€‰ï¼‰")
binary_cols = [col for col in df.columns if df[col].nunique() == 2]

if not binary_cols:
    st.error("âŒ æ•°æ®ä¸­æ²¡æœ‰äºŒåˆ†ç±»å˜é‡ï¼Œæ— æ³•è®­ç»ƒ Logit æ¨¡å‹ã€‚")
    st.stop()

st.write("**å¯ç”¨äºé¢„æµ‹çš„ç›®æ ‡å˜é‡ï¼ˆYï¼‰ï¼š**")
st.write(binary_cols)

selected_targets = st.sidebar.multiselect(
    "è¯·é€‰æ‹©ç”¨äºé¢„æµ‹çš„ç›®æ ‡ï¼ˆå¯å¤šé€‰ï¼‰ï¼š",
    options=binary_cols,
    default=binary_cols,  # é»˜è®¤å…¨é€‰æ‰€æœ‰äºŒåˆ†ç±»å˜é‡
)

if not selected_targets:
    st.warning("âš  è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç›®æ ‡å˜é‡ã€‚")
    st.stop()

# 3ï¸âƒ£ é€‰æ‹©ç‰¹å¾å˜é‡ Xï¼ˆé»˜è®¤ä½¿ç”¨æ‰€æœ‰æ•°å€¼å‹åˆ—ï¼‰
st.sidebar.header("3ï¸âƒ£ é€‰æ‹©ç‰¹å¾ X")
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

if not numeric_cols:
    st.error("âŒ æ²¡æœ‰æ•°å€¼å‹ç‰¹å¾åˆ—ï¼Œæ— æ³•è®­ç»ƒ Logit æ¨¡å‹ã€‚")
    st.stop()

feature_cols = st.sidebar.multiselect(
    "é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆXï¼‰", options=numeric_cols, default=numeric_cols
)

if not feature_cols:
    st.error("âš  è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾å˜é‡ã€‚")
    st.stop()

# 4ï¸âƒ£ è®¾ç½®è®­ç»ƒå‚æ•°
st.sidebar.header("4ï¸âƒ£ è®­ç»ƒå‚æ•°è®¾ç½®")
test_size = st.sidebar.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.4, 0.3, step=0.05)
random_state = st.sidebar.number_input("éšæœºç§å­", value=42, step=1)

# ğŸš€ è®­ç»ƒæŒ‰é’®
if st.sidebar.button("å¼€å§‹è®­ç»ƒæ‰€æœ‰æ¨¡å‹"):
    results = []

    for target in selected_targets:
        st.markdown(f"---\n### ğŸ¯ ç›®æ ‡å˜é‡ï¼š`{target}`")

        # 1. æ„é€  X, y
        X = df[feature_cols].copy()
        if target in X.columns:
            X = X.drop(columns=[target])  # é¿å…ç›®æ ‡å˜é‡æ··å…¥ç‰¹å¾

        y = df[target]

        # å†æ¬¡ç¡®è®¤æ˜¯äºŒåˆ†ç±»
        if y.nunique() != 2:
            st.warning(f"`{target}` ä¸æ˜¯äºŒåˆ†ç±»ï¼Œè·³è¿‡ã€‚")
            continue

        # 2. åˆå¹¶åç»Ÿä¸€æ¸…æ´— NaN / Inf
        data_xy = pd.concat([X, y], axis=1)

        # æ›¿æ¢æ— ç©·ä¸º NaN
        data_xy = data_xy.replace([np.inf, -np.inf], np.nan)

        # ä¸¢å¼ƒå« NaN çš„è¡Œ
        before = len(data_xy)
        data_xy = data_xy.dropna()
        after = len(data_xy)

        if after < 50:
            st.warning(f"`{target}` æ¸…æ´—ååªå‰© {after} æ¡æ ·æœ¬ï¼Œæ ·æœ¬å¤ªå°‘ï¼Œè·³è¿‡ã€‚")
            continue

        st.write(f"âœ… ç›®æ ‡ `{target}`ï¼šå·²åˆ é™¤å«ç¼ºå¤±å€¼æˆ–æ— ç©·å€¼çš„æ ·æœ¬ {before - after} æ¡ï¼Œå‰©ä½™ {after} æ¡ã€‚")

        # æ‹†å› X, y
        X_clean = data_xy.drop(columns=[target])
        y_clean = data_xy[target]

        # ç¡®ä¿ä¸¤ç±»æ ·æœ¬éƒ½è¿˜åœ¨
        if y_clean.nunique() != 2:
            st.warning(f"`{target}` æ¸…æ´—ååªå‰©ä¸€ä¸ªç±»åˆ«ï¼Œæ— æ³•è®­ç»ƒï¼Œè·³è¿‡ã€‚")
            continue

        # 3. åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
        try:
            X_train, X_test, y_train, y_test = train_test_split(
                X_clean, y_clean,
                test_size=test_size,
                random_state=random_state,
                stratify=y_clean
            )
        except ValueError as e:
            st.warning(f"`{target}` åœ¨åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†æ—¶å‡ºé”™ï¼š{e}ï¼Œè·³è¿‡ã€‚")
            continue

        # 4. è®­ç»ƒé€»è¾‘å›å½’ï¼ˆLogitï¼‰
        model = LogisticRegression(max_iter=1000, solver="liblinear")
        try:
            model.fit(X_train, y_train)
        except ValueError as e:
            st.warning(f"`{target}` åœ¨è®­ç»ƒæ¨¡å‹æ—¶å‡ºé”™ï¼š{e}ï¼Œè·³è¿‡ã€‚")
            continue

        # 5. é¢„æµ‹ä¸è¯„ä¼°
        y_pred = model.predict(X_test)
        try:
            y_proba = model.predict_proba(X_test)[:, 1]
        except Exception:
            y_proba = None

        acc = accuracy_score(y_test, y_pred)
        st.write(f"- Accuracyï¼š**{acc:.4f}**")

        if y_proba is not None and y_test.nunique() == 2:
            try:
                auc = roc_auc_score(y_test, y_proba)
                st.write(f"- ROC-AUCï¼š**{auc:.4f}**")
            except ValueError:
                auc = np.nan
                st.write("- ROC-AUCï¼šæ— æ³•è®¡ç®—ï¼ˆå¯èƒ½æ˜¯é¢„æµ‹æ¦‚ç‡å¼‚å¸¸ï¼‰")
        else:
            auc = np.nan
            st.write("- ROC-AUCï¼šæ— æ³•è®¡ç®—")

        # 6. ä¿å­˜ç»“æœç”¨äºæ±‡æ€»
        results.append({
            "Target (Y)": target,
            "Accuracy": round(acc, 4),
            "ROC-AUC": round(auc, 4) if not np.isnan(auc) else None
        })

    # 7. æ±‡æ€»ç»“æœè¡¨
    if results:
        st.subheader("ğŸ“Š æ‰€æœ‰æ¨¡å‹è¡¨ç°å¯¹æ¯”")
        st.dataframe(pd.DataFrame(results))
    else:
        st.warning("âš  æ²¡æœ‰æˆåŠŸè®­ç»ƒä»»ä½•æ¨¡å‹ã€‚")
else:
    st.info("ğŸ‘ˆ è®¾ç½®å®Œæˆåï¼Œç‚¹å‡»å·¦ä¾§æŒ‰é’®å¼€å§‹è®­ç»ƒæ‰€æœ‰æ¨¡å‹ã€‚")
